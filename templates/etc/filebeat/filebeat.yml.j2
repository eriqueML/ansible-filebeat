#=========================== Filebeat inputs =============================

filebeat.inputs:

- type: {{ filebeat_inputs_type }}
  
  enabled: {{ filebeat_inputs_enabled }}

  # Paths that should be crawled and fetched. Glob based paths.
  {% if filebeat_inputs_enabled %}
  
  paths: 
    - {{ filebeat_inputs_path }}

  exclude_lines: ['^DBG']

  include_lines: ['^ERR', '^WARN']

  exclude_files: ['.gz$']

  # Optional additional fields. These fields can be freely picked
  # to add additional information to the crawled log files for filtering
  fields:
    level: debug
    review: 1

  ### Multiline options
  # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [
  multiline.pattern: ^\[

  # Defines if the pattern set under pattern should be negated or not. Default is false.
  multiline.negate: false

  # Match can be set to "after" or "before".
  multiline.match: after
  
  {% endif %}

#============================= Filebeat modules ===============================

filebeat.config.modules:
  # Glob pattern for configuration loading
  path: ${path.config}/modules.d/*.yml

  # Set to true to enable config reloading
  reload.enabled: false

  # Period on which files under path should be checked for changes
  #reload.period: 10s

#==================== Elasticsearch template setting ==========================

setup.template.settings:
  index.number_of_shards: 1
  #index.codec: best_compression
  #_source.enabled: false

#================================ General =====================================

# The name of the shipper that publishes the network data. It can be used to group
# all the transactions sent by a single shipper in the web interface.
#name:

# The tags of the shipper are included in their own field with each
# transaction published.
#tags: ["service-X", "web-tier"]

# Optional fields that you can specify to add additional information to the
# output.
#fields:
#  env: staging

#============================== Dashboards =====================================

#setup.dashboards.enabled: false

#setup.dashboards.url:

{% if filebeat_kibana %}
#============================== Kibana =====================================
 
setup.kibana:
  host: "{{ filebeat_kibana_url }}"
{% if filebeat_kibana_spaceid %}
  space.id: {{ filebeat_kibana_spaceid }}
{% endif %}  
{% endif %}

#================================ Outputs =====================================

{% if filebeat_kafka_output_enabled %}
#-------------------------- Kafka output --------------------------------------

output.kafka:
  hosts: {{ filebeat_kafka_hosts | to_json }}
  topic: '{{ filebeat_kafka_topic }}'
{% endif%}

{% if filebeat_elasticsearch_output_enabled %}
#-------------------------- Elasticsearch output ------------------------------

output.elasticsearch:
  hosts: {{ filebeat_elasticsearch_hosts | to_json }}
  
  protocol: "{{ filebeat_elasticsearch_url_protocol }}"
  {% if filebeat_elasticsearch_apikey %}
  api_key: "id:api_key"
  {% endif %}
  {% if filebeat_elasticsearch_username is defined %}
  
  username: "{{ filebeat_elasticsearch_username }}"
  password: "{{ filebeat_elasticsearch_password }}"
  
  {% endif %}
{% endif %}
{% if filebeat_logstash_output_enabled %}
#----------------------------- Logstash output --------------------------------

output.logstash:

  # The Logstash hosts
  hosts: {{ filebeat_logstash_hosts }}

  # Optional SSL. By default is off.
  # List of root certificates for HTTPS server verifications
  #ssl.certificate_authorities: ["/etc/pki/root/ca.pem"]

  # Certificate for SSL client authentication
  #ssl.certificate: "/etc/pki/client/cert.pem"

  # Client Certificate Key
  #ssl.key: "/etc/pki/client/cert.key"
{% endif %}

#================================ Processors =====================================

# Configure processors to enhance or manipulate events generated by the beat.

processors:
  - add_host_metadata: ~
  - add_cloud_metadata: ~
  - add_docker_metadata: ~
  - add_kubernetes_metadata: ~

#================================ Logging =====================================

logging.level: {{ filebeat_logging_level }}
{% if filebeat_logging_to_files %}
logging.to_files: {{ filebeat_logging_to_files }}
{% endif %}
logging.files: 
{{ filebeat_logging_files_props | to_nice_yaml(indent=2) | indent(2, true) }}

#logging.selectors: ["*"]

#============================== X-Pack Monitoring ===============================
# filebeat can export internal metrics to a central Elasticsearch monitoring
# cluster.  This requires xpack monitoring to be enabled in Elasticsearch.  The
# reporting is disabled by default.

# Set to true to enable the monitoring reporter.
#monitoring.enabled: false

# Sets the UUID of the Elasticsearch cluster under which monitoring data for this
# Filebeat instance will appear in the Stack Monitoring UI. If output.elasticsearch
# is enabled, the UUID is derived from the Elasticsearch cluster referenced by output.elasticsearch.
#monitoring.cluster_uuid:

# Uncomment to send the metrics to Elasticsearch. Most settings from the
# Elasticsearch output are accepted here as well.
# Note that the settings should point to your Elasticsearch *monitoring* cluster.
# Any setting that is not set is automatically inherited from the Elasticsearch
# output configuration, so if you have the Elasticsearch output configured such
# that it is pointing to your Elasticsearch monitoring cluster, you can simply
# uncomment the following line.
#monitoring.elasticsearch:

#================================= Migration ==================================

# This allows to enable 6.7 migration aliases
#migration.6_to_7.enabled: true
